{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala as dependências\n",
    "!pip install -r ../../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evitando logs no plot de gráficos\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/tratado/dados_cvm_tratados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna criada para futura comparação gráfica\n",
    "df['Razao_Inadimplencia_Provisao'] = df['Inadimplencia_Total'] / df['Provisao_Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_treinamento = df.drop([\"ID_Participante\", \"Data_Competencia\"], axis=1) # para treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualização\n",
    "Tendo em vista o desafio de prever, através de um modelo de *machine learning*, as perdas financeiras e o mal provisionamento nos fundos de investimento em direitos creditórios (FIDCS), uma possível abordagem seria a identificação de fundos que compartilham de um comportamento semelhante por meio da clusterização. Um dos mais conhecidos algoritmos não supervisionados de agrupamento é o *K-Means*, que funciona de forma similar ao KNN e seu sistema de delimitação dos \"nearest neighbours\" ou vizinhos mais próximos.\n",
    "\n",
    "Alguns dos pontos fortes desse algoritmo são sua eficiência computacional, seu caráter não supervisionado e sua simplicidade e facilidade de implementação e interpretação, motivos os quais tornaram indispensável a realização de um teste de comparação com o algoritmo. Entretanto, a simplicidade do algoritmo e sua dificuldade em detectar anomalias ou *outliers* podem ser um problema considerando os dados com os quais o grupo FIDCAS está trabalhando.\n",
    "\n",
    "Concluímos anterior e provisoriamente que a clusterização não seria nosso objetivo central, dada a dificuldade de realizar agrupamentos com dados tão dispersos e distintos. Entretanto, com a nova abordagem de divisão dos fundos por carteira que foi adotada pelo grupo FIDCAS e com a necessidade de comparação de modelos para ratificar ou não a adesão definitiva ao modelo *Isolation Forest*, é preciso testar a possibilidade de clusterização dos fundos, que pode ser facilitada e mais efetiva devido à maior semelhança entre fundos de mesma carteira.\n",
    "\n",
    "Logo, as seguintes seções desse notebook se destinam à modelagem com utilização do algoritmo *K-Means* das diferentes divisões de dados, feitas de acordo com o agrupamento das diferentes carteiras, e à avaliação dos resultados da mesma. Foram utilizadas as mesmas *features* aplicadas na implementação do *Isolation Forest*, pois ele parece atingir resultados satisfatórios com elas. Portanto, procuramos um modelo que supere seu desempenho utilizando características semelhantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação de fundos por carteira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o algoritmo de LabelEncoding, foi criada a coluna \"Carteira_Classificacao_Encoded\", que apresenta números que identificam fundos de diversas carteiras. Nesse contexto, as labels numéricas criadas são definidas da seguinte forma:\n",
    "\n",
    "Setor Público = 0\n",
    "\n",
    "Agronegócio = 1\n",
    "\n",
    "Cartão = 2\n",
    "\n",
    "Comercial = 3\n",
    "\n",
    "Imobiliário = 4\n",
    "\n",
    "Financeiro = 5\n",
    "\n",
    "Industrial = 6\n",
    "\n",
    "Factoring = 7\n",
    "\n",
    "Multimercado = 8\n",
    "\n",
    "Serviços = 9\n",
    "\n",
    "Ações Judiciais = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de carteiras com índices correspondentes à classificação\n",
    "classificacao_encoding = [\n",
    "    'SetorPublico',\n",
    "    'Agronegocio',\n",
    "    'Cartao',\n",
    "    'Comercial',\n",
    "    'Imobiliario',\n",
    "    'Financeiro',\n",
    "    'Industrial',\n",
    "    'Factoring',\n",
    "    'Multimercado',\n",
    "    'Servicos',\n",
    "    'AcoesJudiciais'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados por carteira\n",
    "dados_classificacao = {\n",
    "    'Setor Público': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('SetorPublico')],\n",
    "    'Agronegócio': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Agronegocio')],\n",
    "    'Cartão': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Cartao')],\n",
    "    'Comercial': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Comercial')],\n",
    "    'Imobiliário': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Imobiliario')],\n",
    "    'Financeiro': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Financeiro')],\n",
    "    'Industrial': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Industrial')],\n",
    "    'Factoring': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Factoring')],\n",
    "    'Multimercado': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Multimercado')],\n",
    "    'Serviços': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('Servicos')],\n",
    "    'Ações Judiciais': df_para_treinamento.loc[df_para_treinamento['Carteira_Classificação_encoded'] == classificacao_encoding.index('AcoesJudiciais')]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_distancias_k(dados : pd.DataFrame):\n",
    "    '''\n",
    "    Calcula e retorna a soma das distâncias quadradas retornadas\n",
    "    pelo modelo treinado com diferentes números de clusters (1 a 11).\n",
    "\n",
    "    ## Parâmetros\n",
    "    dados (pd.Dataframe): O DataFrame a ser usado para cálculo das distâncias.\n",
    "\n",
    "    ## Retorna\n",
    "    Lista das distâncias relativas a cada número de clusters, sendo esses\n",
    "    calculados em ordem crescente. \n",
    "    '''\n",
    "    wcss = []\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(dados)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "\n",
    "    return wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_melhor_k(dados : pd.DataFrame, distancias : list = []):\n",
    "    '''\n",
    "    Calcula e retorna o melhor valor de K para treinamento do modelo baseado\n",
    "    na soma das distâncias quadradas calculadas para cada número de clusters.\n",
    "\n",
    "    ## Parâmetros\n",
    "    dados (pd.Dataframe): O DataFrame a ser usado para cálculo das distâncias\n",
    "    e do K.\n",
    "    \n",
    "    distancias (list): Caso já se tenha as distâncias calculadas em uma lista,\n",
    "    é possível passar como parâmetro para não realizar o cálculo novamente.\n",
    "    Necessário que a lista esteja ordenada de acordo com a ordem crescente de\n",
    "    número de clusters.\n",
    "\n",
    "    ## Retorna\n",
    "    O melhor valor de K calculado.\n",
    "    '''\n",
    "\n",
    "    if len(distancias):\n",
    "        wcss = distancias\n",
    "    else:\n",
    "        wcss = calcula_distancias_k(dados.drop(['Razao_Inadimplencia_Provisao'], axis=1))\n",
    "\n",
    "    x1, y1 = 2, wcss[0]\n",
    "    x2, y2 = len(wcss), wcss[-1]\n",
    "\n",
    "    distances = []\n",
    "    for i in range(len(wcss)):\n",
    "        x0 = i+2\n",
    "        y0 = wcss[i]\n",
    "        numerator = abs((y2-y1)*x0 - (x2-x1)*y0 + x2*y1 - y2*x1)\n",
    "        denominator = sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
    "        distances.append(numerator/denominator)\n",
    "    \n",
    "    return distances.index(max(distances)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_plot(dados : pd.DataFrame, classificacao : str):\n",
    "    '''\n",
    "    Constrói um gráfico no formato \"Elbow Plot\" para encontrar o valor ótimo\n",
    "    de K para o treinamento do modelo *K-Means* e printa o esse valor de K.\n",
    "\n",
    "    ## Parâmetros\n",
    "    dados (pd.Dataframe): O DataFrame a ser usado para cálculo das distâncias\n",
    "    e do K.\n",
    "    \n",
    "    classificacao (string): O tipo de carteira dos fundos sendo analizados\n",
    "    (presentes no parâmetros \"dados\").\n",
    "\n",
    "    ## Retorna\n",
    "    None.\n",
    "    '''\n",
    "\n",
    "    distancias = calcula_distancias_k(dados)\n",
    "\n",
    "    graph = plt.plot(range(1, 11), distancias, marker='o')\n",
    "    plt.title(f'{classificacao}: Elbow Method')\n",
    "    plt.xlabel('Número de clusters')\n",
    "    plt.ylabel('Distâncias')\n",
    "    plt.show()\n",
    "\n",
    "    melhor_k = calcula_melhor_k(dados, distancias)\n",
    "    print(f'O melhor valor de K para a carteira de {classificacao} é {melhor_k}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de gráficos para cada divisão de dados por carteira\n",
    "for classificacao in dados_classificacao.keys():\n",
    "    elbow_plot(dados_classificacao[classificacao].drop('Razao_Inadimplencia_Provisao', axis=1), classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_grafico_dispersao(x : pd.Series, y : pd.Series, carteira : str):\n",
    "    '''\n",
    "    Constrói gráfico de dispersão relacionando duas colunas de um DataFrame.\n",
    "\n",
    "    ## Parâmetros\n",
    "    x (pd.Series): A coluna do eixo X do gráfico.\n",
    "    \n",
    "    y (pd.Series): A coluna do eixo Y do gráfico.\n",
    "    \n",
    "    carteira (string): O tipo de carteira dos fundos sendo analizados\n",
    "    no gráfico. Opcional, apenas compõe o título do gráfico.\n",
    "\n",
    "    ## Retorna\n",
    "    None.\n",
    "    '''\n",
    "    graph = plt.scatter(x, y, c=x)\n",
    "    if carteira:\n",
    "        plt.title(f'{carteira}: {x.name} x {y.name}')\n",
    "    else:\n",
    "        plt.title(f'{x.name} x {y.name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_kmeans(dados : pd.DataFrame, classificacao : str):\n",
    "    '''\n",
    "    Realiza todas as operações relativas ao treinamento dos modelos com o algoritmo *K-Means*.\n",
    "    Constrói gráfico de dispersão relacionando os clusters e a inadimplência total.\n",
    "\n",
    "    ## Parâmetros\n",
    "    dados (pd.DataFrame): O DataFrame a ser usado para cálculo das distâncias\n",
    "    e do K.\n",
    "    \n",
    "    classificacao (string): O tipo de carteira dos fundos sendo analizados\n",
    "    (presentes no parâmetros \"dados\").\n",
    "\n",
    "    ## Retorna\n",
    "    None.\n",
    "    '''\n",
    "    k = calcula_melhor_k(dados)\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10)\n",
    "    kmeans.fit_predict(dados.drop(['Razao_Inadimplencia_Provisao'], axis=1))\n",
    "    dados['Cluster'] = kmeans.labels_\n",
    "\n",
    "    plota_grafico_dispersao(dados['Cluster'], dados['Razao_Inadimplencia_Provisao'], classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino de modelo e plot de gráficos para cada divisão de dados por carteira\n",
    "for classificacao in dados_classificacao.keys():\n",
    "    pipeline_kmeans(dados_classificacao[classificacao], classificacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "O modelo desenvolvido com o algoritmo *K-Means* gerou resultados que diferem daqueles produzidos pelo *Isolation Forest* principalmente pela questão da clusterização realizada pelo primeiro em comparação à indicação do nível de anormalidade exposto pelo segundo. De forma geral, enquanto o *K-Means* agrupa dados que compartilham de características semelhantes em um K número de *clusters*, o *Isolation Forest* classifica os dados em anômalos (classificação \"-1\" do modelo) e normais (classificação \"1\" do modelo).\n",
    "\n",
    "Devido à simplicidade do algoritmo *K-Means*, ele enfrenta dificuldades ao lidar com outliers e apresenta um desempenho não muito positivo ao trabalhar com *clusters* de formatos não convexos, ou seja, o modelo gerado não é apropriado para manusear dados com comportamentos tão distintos e sem padrão observável como os presentes no *dataset* do projeto. Ainda assim, para fins comparativos e de teste, o grupo realizou a modelagem para analisar os resultados gerados, buscando encontrar agrupamentos de fundos problemáticos nos diferentes tipos de carteira.\n",
    "\n",
    "Com o desafio de comparar resultados de diferentes modelos não supervisionados e que ainda possuem processos tão diferentes de funcionamento em vista, criou-se a coluna \"Razao_Inadimplencia_Provisao\", uma medida que indica o quão maior que a provisão é a inadimplência (quanto maior o valor contido na coluna, maior a inadimplência em relação à provisão), dado que essas são duas *features* centrais e fundamentais para os objetivos do projeto e para análise de fundos problemáticos.\n",
    "\n",
    "Além disso, também foi implementada a função \"calcula_melhor_k\", cujo objetivo é definido por encontrar o valor ótimo de K (número de *clusters* a serem gerados pelo modelo) para cada tipo diferente de carteira, a fim de maximizar a eficácia do algoritmo *K-Means*. Ela calcula esse valor encontrando o ponto no gráfico que mais se distancia da reta traçada entre o valor da soma das distâncias quadradas quando se treina o modelo com um *cluster* (em outras palavras, o primeiro ponto do gráfico de cotovelo, o qual possui o mais elevado valor de y) e o mesmo valor para o treinamento com onze *clusters* (máximo de *clusters* para testagem definido arbitrariamente; ponto com menor valor de y no gráfico de cotovelo). Esse ponto mais distante corresponde ao cotovelo do gráfico.\n",
    "\n",
    "Com a construção de gráficos que demonstram a relação entre essa a razão entre a inadimplência e a provisão e os *clusters* gerados pelo algoritmo, é possível visualizar que os diferentes *clusters* contêm dados que compartilham certa semelhança no que tange essa característica da razão. Há *outliers* e eles tendem a estar mais presentes em um único *cluster*, porém, em todos os casos, esse mesmo cluster também apresenta uma grande quantidade de dados semelhantes aos presentes em outros agrupamentos. Ou seja, mesmo que fossem usados esses grupos de dados aparentemente anômalos, seria difícil filtrar o que realmente seria um fundo em risco, gerando um grande número de \"falsos positivos\".\n",
    "\n",
    "Portanto, concluiu-se que o modelo não é o mais apropriado para construção da solução esperada no projeto quando comparado ao desenvolvido com o algoritmo *Isolation Forest*, tanto por sua dificuldade de classificar dados anômalos precisamente com o *dataset* utilizado quanto por trabalhar com clusterização e identificação de padrões, que não é a intenção principal do projeto considerando o caráter caótico dos dados. Ademais, sua simplicidade e consequentes limitações também prejudicam sua avaliação comparativa, haja vista a complexidade e os variados comportamentos dos dados com os quais o grupo FIDCAS está trabalhando.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
