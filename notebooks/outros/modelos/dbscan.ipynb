{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala as dependências\n",
    "!pip install -r ../../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evitando logs no plot de gráficos\\n\",\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos dados_tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_tratados = pd.read_csv('../../../data/tratado/dados_cvm_tratados.csv')\n",
    "dados_tratados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_tratados['Razao_Inadimplencia_Provisao'] = dados_tratados['Inadimplencia_Total'] / dados_tratados['Provisao_Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualização\n",
    "Seguindo o mesmo raciocínio explicitado no *notebook* referente ao modelo *K-Means*, as seções abaixo se destinam à construção de um modelo de clusterização utilizando o algoritmo *DBSCAN* para servir de comparação à modelagem realizada com o algoritmo *Isolation Forest*. Também foi feita a modelagem com a separação dos fundos por carteira e com as mesmas *features* utilizadas no *notebook* referente ao modelo *Isolation Forest*.\n",
    "\n",
    "O *DBSCAN* é um algoritmo de agupamento popular por se diferenciar dos sistemas mais comuns, como o próprio *K-Means*, em seus processos de clusterização: ele define arbitrariamente a quantidade de *clusters* resultantes e identifica *clusters* de diferentes formatos e densidades de pontos com certa facilidade. Além disso, o *DBSCAN* é eficiente computacionalmente e lida bem com ruído, ou seja, é capaz de identificar e isolar *outliers*. Portanto, esse algoritmo pode ser uma excelente escolha, especialmente quando não se sabe previamente quantos *clusters* esperar e quando os *clusters* têm formas irregulares e densidades variáveis, que pode ser o caso do nosso projeto, considerando o caráter caótico dos dados que possuímos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação dos fundos por carteira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o algoritmo de LabelEncoding, foi criada a coluna \"Carteira_Classificacao_Encoded\", que apresenta números que identificam fundos de diversas carteiras. Nesse contexto, as labels numéricas criadas são definidas da seguinte forma:\n",
    "\n",
    "Setor Público = 0\n",
    "\n",
    "Agronegócio = 1\n",
    "\n",
    "Cartão = 2\n",
    "\n",
    "Comercial = 3\n",
    "\n",
    "Imobiliário = 4\n",
    "\n",
    "Financeiro = 5\n",
    "\n",
    "Industrial = 6\n",
    "\n",
    "Factoring = 7\n",
    "\n",
    "Multimercado = 8\n",
    "\n",
    "Serviços = 9\n",
    "\n",
    "Ações Judiciais = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de carteiras com índices correspondentes à classificação\n",
    "classificacao_encoding = [\n",
    "    'SetorPublico',\n",
    "    'Agronegocio',\n",
    "    'Cartao',\n",
    "    'Comercial',\n",
    "    'Imobiliario',\n",
    "    'Financeiro',\n",
    "    'Industrial',\n",
    "    'Factoring',\n",
    "    'Multimercado',\n",
    "    'Servicos',\n",
    "    'AcoesJudiciais'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados por carteira\n",
    "dados_classificacao = {\n",
    "    'Setor Público': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('SetorPublico')],\n",
    "    'Agronegócio': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Agronegocio')],\n",
    "    'Cartão': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Cartao')],\n",
    "    'Comercial': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Comercial')],\n",
    "    'Imobiliário': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Imobiliario')],\n",
    "    'Financeiro': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Financeiro')],\n",
    "    'Industrial': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Industrial')],\n",
    "    'Factoring': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Factoring')],\n",
    "    'Multimercado': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Multimercado')],\n",
    "    'Serviços': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('Servicos')],\n",
    "    'Ações Judiciais': dados_tratados.loc[dados_tratados['Carteira_Classificação_encoded'] == classificacao_encoding.index('AcoesJudiciais')]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Começo da modelagem com *DBSCAN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_grafico_dispersao(x : pd.Series, y : pd.Series, carteira : str):\n",
    "    '''\n",
    "    Constrói gráfico de dispersão relacionando duas colunas de um DataFrame.\n",
    "\n",
    "    ## Parâmetros\n",
    "    x (pd.Series): A coluna do eixo X do gráfico.\n",
    "    \n",
    "    y (pd.Series): A coluna do eixo Y do gráfico.\n",
    "    \n",
    "    carteira (string): O tipo de carteira dos fundos sendo analizados\n",
    "    no gráfico. Opcional, apenas compõe o título do gráfico.\n",
    "\n",
    "    ## Retorna\n",
    "    None.\n",
    "    '''\n",
    "    graph = plt.scatter(x, y, c=x)\n",
    "    if carteira:\n",
    "        plt.title(f'{carteira}: {x.name} x {y.name}')\n",
    "    else:\n",
    "        plt.title(f'{x.name} x {y.name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_dbscan(dados : pd.DataFrame, eps : float, min_samples : int, classificacao : str):\n",
    "    '''\n",
    "    Realiza todas as operações relativas ao treinamento dos modelos com o algoritmo DBSCAN.\n",
    "    Constrói gráfico de dispersão relacionando os clusters e a inadimplência total.\n",
    "\n",
    "    ## Parâmetros\n",
    "    dados (pd.DataFrame): O DataFrame a ser usado para cálculo das distâncias\n",
    "    e do K.\n",
    "\n",
    "    eps (float): A distância máxima entre dois pontos nos dados para que sejam\n",
    "    considerados vizinhos.\n",
    "    \n",
    "    min_samples (int): O número mínimo de amostras (ou peso total) em um conjunto\n",
    "    para que um ponto seja considerado um ponto central na clusterização (incluindo\n",
    "    ele mesmo).\n",
    "    \n",
    "    classificacao (string): O tipo de carteira dos fundos sendo analizados\n",
    "    (presentes no parâmetros \"dados\").\n",
    "\n",
    "    ## Retorna\n",
    "    None.\n",
    "    '''\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    clusters = db.fit_predict(dados.drop(['ID_Participante', 'Data_Competencia', 'Razao_Inadimplencia_Provisao'], axis=1))\n",
    "    dados['cluster'] = clusters\n",
    "    plota_grafico_dispersao(dados['cluster'], dados['Razao_Inadimplencia_Provisao'], classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino de modelo e plot de gráficos para cada divisão de dados por carteira\n",
    "for classificacao in dados_classificacao.keys():\n",
    "    pipeline_dbscan(dados_classificacao[classificacao], 0.5, 20, classificacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "A principal diferença entre os resultados gerados pelos algoritmos *DBSCAN* e *Isolation Forest* se refere à clusterização realizada pelo primeiro em comparação à indicação do nível de anormalidade exposto pelo segundo. Ou seja, enquanto o *DBSCAN* agrupa dados que compartilham de características semelhantes em um ou mais *clusters* e isola ruídos, o *Isolation Forest* classifica os dados como anômalos (classificação \"-1\" do modelo) ou normais (classificação \"1\" do modelo).\n",
    "\n",
    "Pelo raciocínio de detectação de anomalias ou ruídos, não é possível avaliar positivamente o desempenho do algoritmo *DBSCAN*, porque, segundo a documentação, os dados anômalos ou ruidosos são alocados no *cluster* \"-1\", o qual foi criado para poucos tipos de carteira no processo de modelagem e não apresenta muitos resultados relevantes. Por isso, o grupo partiu para a análise geral dos *clusters* gerados, buscando encontrar agrupamentos de fundos problemáticos que não estivessem classificados como \"-1\" nos diferentes tipos de carteira.\n",
    "\n",
    "Com o desafio de comparar resultados de diferentes modelos não supervisionados e que ainda possuem processos tão diferentes de funcionamento em vista, criou-se a coluna \"Razao_Inadimplencia_Provisao\", uma medida que indica o quão maior que a provisão é a inadimplência (quanto maior o valor contido na coluna, maior a inadimplência em relação à provisão), dado que essas são duas *features* centrais e fundamentais para os objetivos do projeto e para análise de fundos problemáticos.\n",
    "\n",
    "Com a construção de gráficos que demonstram a relação entre essa razão e os *clusters* gerados pelo algoritmo, é possível visualizar que os diferentes *clusters* contêm dados que compartilham certa semelhança no que tange essa característica da razão. Há *outliers* e eles tendem a estar mais presentes em um único *cluster*, porém, em todos os casos, esse mesmo *cluster* também apresenta uma grande quantidade de dados semelhantes aos presentes em outros agrupamentos. Ou seja, mesmo que fossem usados esses grupos de dados aparentemente anômalos, seria difícil filtrar o que realmente seria um fundo em risco, gerando um grande número de \"falsos positivos\".\n",
    "\n",
    "Portanto, concluiu-se que o modelo não é o mais apropriado para construção da solução esperada no projeto quando comparado ao desenvolvido com o algoritmo *Isolation Forest*, tanto por sua dificuldade de classificar dados anômalos precisamente com o *dataset* utilizado quanto por trabalhar com clusterização e identificação de padrões, que não é a intenção principal do projeto considerando o caráter caótico dos dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
